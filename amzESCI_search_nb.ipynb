{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 5)) (1.8.0.post1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 6)) (4.66.5)\n",
      "Requirement already satisfied: rank-bm25 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 9)) (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 10)) (3.9.2)\n",
      "Requirement already satisfied: flask in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 11)) (3.0.3)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 12)) (17.0.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from -r requirements.txt (line 13)) (2024.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\owner\\appdata\\roaming\\python\\python312\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (4.44.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (0.24.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (10.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\owner\\appdata\\roaming\\python\\python312\\site-packages (from faiss-cpu->-r requirements.txt (line 5)) (23.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\owner\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 10)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 10)) (3.1.4)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from flask->-r requirements.txt (line 11)) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from flask->-r requirements.txt (line 11)) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from flask->-r requirements.txt (line 11)) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from flask->-r requirements.txt (line 11)) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from flask->-r requirements.txt (line 11)) (1.8.2)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from fastparquet->-r requirements.txt (line 13)) (2.8.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from fastparquet->-r requirements.txt (line 13)) (2024.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (3.16.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from Jinja2>=3.1.2->flask->-r requirements.txt (line 11)) (2.1.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\owner\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (72.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->-r requirements.txt (line 4)) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->-r requirements.txt (line 4)) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->-r requirements.txt (line 4)) (0.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\owner\\desktop\\graingertakehome\\.conda\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook demonstrates the process of loading, preprocessing, and analyzing Amazon product data using various machine learning techniques. The main objectives are to generate embeddings, build search indices, and evaluate search performance using semantic and hybrid search methods.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_22328\\2001978341.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(sample_size=1, random_state=42):\n",
    "    \"\"\"\n",
    "    Loads the shopping queries and product datasets, filters by conditions, merges the datasets, and optionally samples the data.\n",
    "    We filter to use the small version of dataset with US locale only, as well as random (non-stratified) sampling for faster embedding and indexing.\n",
    "    \n",
    "    P.S. removing special characters and puntuation lead to worse semantic search results (r'[^a-zA-Z0-9\\s])\n",
    "    Using PCA to reduce dimentions also lead to worse semantic results\n",
    "    Loading chunks disabled as there is no memory contraint assumed\n",
    "    \n",
    "    Parameters:\n",
    "    sample_size (float): The fraction of data to sample. Default is 1.0 (no sampling).\n",
    "    random_state (int): Seed for reproducibility of sampling. Default is 42.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Preprocessed dataframe.\n",
    "    \"\"\"\n",
    "        \n",
    "    base_url = \"https://github.com/amazon-science/esci-data/raw/main/shopping_queries_dataset\"\n",
    "    \n",
    "    print(\"Loading examples dataset...\")\n",
    "    df_examples = pd.read_parquet(f'{base_url}/shopping_queries_dataset_examples.parquet')\n",
    "    \n",
    "    print(\"Loading products dataset...\")\n",
    "    df_products = pd.read_parquet(f'{base_url}/shopping_queries_dataset_products.parquet')\n",
    "    \n",
    "    print(\"Filtering data...\")\n",
    "    df_examples = df_examples[(df_examples['small_version'] == 1) & (df_examples['product_locale'] == 'us')]\n",
    "    df_products = df_products[df_products['product_locale'] == 'us']\n",
    "    \n",
    "    print(\"Merging datasets...\")\n",
    "    df = pd.merge(\n",
    "        df_examples,\n",
    "        df_products,\n",
    "        how='left',\n",
    "        on=['product_locale', 'product_id']\n",
    "    )\n",
    "    \n",
    "    if sample_size < 1.0:\n",
    "        print(f\"Sampling {sample_size*100}% of queries...\")\n",
    "        unique_queries = df['query_id'].unique()\n",
    "        np.random.seed(random_state)\n",
    "        sampled_queries = np.random.choice(unique_queries, size=int(len(unique_queries) * sample_size), replace=False)\n",
    "        df = df[df['query_id'].isin(sampled_queries)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, model, batch_size=32):\n",
    "    \"\"\"\n",
    "    This function encodes both the queries and products into embeddings using a pre-trained SentenceTransformer model.\n",
    "    Each product is represented by a combination of product title, description, and bullet points.\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame containing merged query-product data.\n",
    "    - model: Pre-trained SentenceTransformer model for encoding.\n",
    "    - batch_size: Number of examples to encode at once to manage memory.\n",
    "\n",
    "    Returns:\n",
    "    - Encoded query embeddings, product embeddings, and their corresponding unique entries.\n",
    "    \"\"\"\n",
    "\n",
    "    unique_queries = df['query'].unique()\n",
    "    unique_products = df[['product_id', 'product_title', 'product_description', 'product_bullet_point']].drop_duplicates('product_id')\n",
    "    \n",
    "    print(\"Encoding queries...\")\n",
    "    query_embeddings = model.encode(unique_queries.tolist(), batch_size=batch_size, show_progress_bar=True)\n",
    "    \n",
    "    print(\"Encoding products...\")\n",
    "    product_texts = unique_products.apply(lambda row: f\"{row['product_title']} {row['product_description']} {row['product_bullet_point']}\", axis=1).tolist()\n",
    "    product_embeddings = model.encode(product_texts, batch_size=batch_size, show_progress_bar=True)\n",
    "    \n",
    "    return query_embeddings, product_embeddings, unique_queries, unique_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Build search indexes\n",
    "**We build FAISS and BM25 indices to facilitate efficient search.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(embeddings):\n",
    "    \"\"\"\n",
    "    This function builds a FAISS index using the product embeddings for fast similarity search.\n",
    "\n",
    "    Arguments:\n",
    "    - embeddings: Embeddings for the products.\n",
    "\n",
    "    Returns:\n",
    "    - A FAISS index based on the provided embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Building FAISS index...\")\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(embeddings)\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(index, query_embeddings, k=10):\n",
    "    \"\"\"\n",
    "    Perform search on the FAISS index to find the top-k closest products for each query.\n",
    "\n",
    "    Arguments:\n",
    "    - index: Pre-built FAISS index for the products.\n",
    "    - query_embeddings: Embeddings of the queries.\n",
    "    - k: Number of closest products to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - Distances and indices of the top-k nearest products.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Searching index...\")\n",
    "    distances, indices = index.search(query_embeddings, k)\n",
    "    return distances, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(relevance_scores):\n",
    "    \"\"\"Mean Reciprocal Rank: evaluates the first relevant item rank.\"\"\"\n",
    "\n",
    "    reciprocal_ranks = []\n",
    "    for scores in relevance_scores:\n",
    "        rank = next((i + 1 for i, s in enumerate(scores) if s > 0), 0)\n",
    "        reciprocal_ranks.append(1 / rank if rank > 0 else 0)\n",
    "    return np.mean(reciprocal_ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hits_at_n(relevance_scores, n):\n",
    "    \"\"\"Hits@N: checks if at least one relevant item appears in the top N results.\"\"\"\n",
    "\n",
    "    hits = [1 if sum(scores[:n]) > 0 else 0 for scores in relevance_scores]\n",
    "    return np.mean(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg(relevance_scores, k=10):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain: measures ranking quality, penalizing lower-ranked relevant results.\"\"\"\n",
    "\n",
    "    def dcg_at_k(r, k):\n",
    "        r = np.asfarray(r)[:k]\n",
    "        if r.size:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        return 0.\n",
    "\n",
    "    def ndcg_at_k(r, k):\n",
    "        dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
    "        if not dcg_max:\n",
    "            return 0.\n",
    "        return dcg_at_k(r, k) / dcg_max\n",
    "\n",
    "    scores = [ndcg_at_k(r, k) for r in relevance_scores]\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map(relevance_scores):\n",
    "    \"\"\"Mean Average Precision: evaluates precision averaged across different recall levels.\"\"\"\n",
    "\n",
    "    aps = []\n",
    "    for scores in relevance_scores:\n",
    "        precision_at_k = [sum(scores[:k+1]) / (k+1) for k in range(len(scores))]\n",
    "        ap = sum([p * r for p, r in zip(precision_at_k, scores)]) / sum(scores) if sum(scores) > 0 else 0\n",
    "        aps.append(ap)\n",
    "    return np.mean(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_at_k(relevance_scores, k):\n",
    "    \"\"\"Precision@K\"\"\"\n",
    "\n",
    "    return np.mean([sum(scores[:k]) / k for scores in relevance_scores])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(relevance_scores, k):\n",
    "    \"\"\"Recall@k\"\"\"\n",
    "\n",
    "    return np.mean([sum(scores[:k]) / sum(scores) if sum(scores) > 0 else 0 for scores in relevance_scores])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main evaluation funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rankings(df, unique_queries, unique_products, search_results):\n",
    "    \"\"\"\n",
    "    Evaluate the search rankings using various metrics.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataframe containing query and product information.\n",
    "    unique_queries (np.ndarray): Array of unique queries.\n",
    "    unique_products (pd.DataFrame): Dataframe of unique products.\n",
    "    search_results (list): List of search results for each query.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(\"Evaluating rankings...\")\n",
    "    relevance_scores = []\n",
    "    debug_info = []\n",
    "    \n",
    "    # Create a mapping from product ID to index\n",
    "    product_id_to_idx = {pid: idx for idx, pid in enumerate(unique_products['product_id'])}\n",
    "    \n",
    "    # Iterate over each query and its corresponding search results\n",
    "    for query_idx, (query, rankings) in enumerate(zip(unique_queries, search_results)):\n",
    "        scores = []\n",
    "        debug_query = []\n",
    "        \n",
    "        # Filter the dataframe for the current query\n",
    "        query_df = df[df['query'] == query]\n",
    "        \n",
    "        # Get the set of relevant product IDs for the current query\n",
    "        relevant_product_ids = set(query_df[query_df['esci_label'].isin(['E', 'S'])]['product_id'])\n",
    "        \n",
    "        # Iterate over the ranked results\n",
    "        for rank, result in enumerate(rankings):\n",
    "            if isinstance(result, (int, np.integer)):\n",
    "                predicted_product_id = unique_products.iloc[result]['product_id']\n",
    "            else:\n",
    "                predicted_product_id = result\n",
    "            \n",
    "            predicted_product = unique_products.iloc[product_id_to_idx[predicted_product_id]]\n",
    "            predicted_product_title = predicted_product['product_title']\n",
    "            \n",
    "            # Determine if the predicted product is relevant\n",
    "            score = 1 if predicted_product_id in relevant_product_ids else 0\n",
    "            scores.append(score)\n",
    "            \n",
    "            # Add debugging information\n",
    "            debug_query.append(f\"Rank {rank + 1}: ID {predicted_product_id}, Title: {predicted_product_title[:50]}..., Relevant: {'Yes' if score == 1 else 'No'}\")\n",
    "        \n",
    "        relevance_scores.append(scores)\n",
    "        debug_info.append((query, debug_query))\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mrr = calculate_mrr(relevance_scores)\n",
    "    hits_at_1 = calculate_hits_at_n(relevance_scores, 1)\n",
    "    hits_at_5 = calculate_hits_at_n(relevance_scores, 5)\n",
    "    hits_at_10 = calculate_hits_at_n(relevance_scores, 10)\n",
    "    ndcg = calculate_ndcg(relevance_scores)\n",
    "    map_score = calculate_map(relevance_scores)\n",
    "    precision_at_5 = calculate_precision_at_k(relevance_scores, 5)\n",
    "    recall_at_10 = calculate_recall_at_k(relevance_scores, 10)\n",
    "    \n",
    "    # Print debugging information for the first few queries\n",
    "    print(\"\\nDebugging Information:\")\n",
    "    for query, debug in debug_info[:5]:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        for line in debug[:10]:\n",
    "            print(line)\n",
    "    \n",
    "    # Return the evaluation metrics\n",
    "    return {\n",
    "        \"mrr\": mrr,\n",
    "        \"hits@1\": hits_at_1,\n",
    "        \"hits@5\": hits_at_5,\n",
    "        \"hits@10\": hits_at_10,\n",
    "        \"ndcg@10\": ndcg,\n",
    "        \"map\": map_score,\n",
    "        \"precision@5\": precision_at_5,\n",
    "        \"recall@10\": recall_at_10\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return ''.join(char.lower() for char in text if char.isalnum() or char.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bm25_index(corpus):\n",
    "    \"\"\"\n",
    "    Builds a BM25 index from a corpus of product descriptions.\n",
    "    \n",
    "    This method preprocesses the text by lowercasing and removing punctuation, then tokenizes\n",
    "    the corpus into individual terms. It uses the BM25Okapi algorithm to build the index.\n",
    "    \n",
    "    Arguments:\n",
    "    - corpus: List of product descriptions or texts for indexing.\n",
    "    \n",
    "    Returns:\n",
    "    - BM25Okapi object representing the index.\n",
    "    \"\"\"\n",
    "    preprocessed_corpus = [preprocess_text(doc) for doc in corpus]\n",
    "    tokenized_corpus = [doc.split() for doc in preprocessed_corpus]\n",
    "    return BM25Okapi(tokenized_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query, bm25, faiss_index, product_embeddings, query_embedding, products, alpha=0.5, k=10):\n",
    "    \"\"\"\n",
    "    Perform a hybrid search combining BM25 and semantic search scores.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The search query.\n",
    "    bm25 (BM25Okapi): The BM25 index.\n",
    "    faiss_index (faiss.IndexFlatIP): The FAISS index.\n",
    "    product_embeddings (np.ndarray): The product embeddings.\n",
    "    query_embedding (np.ndarray): The query embedding.\n",
    "    products (list): List of product information.\n",
    "    alpha (float): Weight for combining BM25 and semantic scores.\n",
    "    k (int): Number of top results to return.\n",
    "\n",
    "    Returns:\n",
    "    list: Indices of the top k results.\n",
    "    \"\"\"\n",
    "    # Preprocess the query text\n",
    "    preprocessed_query = preprocess_text(query)\n",
    "    \n",
    "    # Get BM25 scores for the query\n",
    "    bm25_scores = bm25.get_scores(preprocessed_query.split())\n",
    "    \n",
    "    # Perform semantic search using FAISS\n",
    "    semantic_distances, semantic_indices = faiss_index.search(query_embedding.reshape(1, -1), k)\n",
    "    \n",
    "    # Normalize semantic scores\n",
    "    semantic_scores = 1 - (semantic_distances[0] / np.max(semantic_distances[0]))\n",
    "    \n",
    "    # Combine BM25 and semantic scores\n",
    "    combined_scores = alpha * bm25_scores[semantic_indices[0]] + (1 - alpha) * semantic_scores\n",
    "    \n",
    "    # Sort indices based on combined scores\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "    \n",
    "    # Return the sorted indices of the top k results\n",
    "    return [semantic_indices[0][i] for i in sorted_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(df, unique_products, unique_queries, product_embeddings, query_embeddings, indices):\n",
    "    result = \"\\nData Inspection:\\n\"\n",
    "    result += f\"Total judgements: {len(df)}\\n\"\n",
    "    result += f\"Unique products: {len(unique_products)}\\n\"\n",
    "    result += f\"Unique queries: {len(unique_queries)}\\n\"\n",
    "    result += f\"Product embeddings shape: {product_embeddings.shape}\\n\"\n",
    "    result += f\"Query embeddings shape: {query_embeddings.shape}\\n\"\n",
    "    \n",
    "    result += \"\\nDistribution of ESCI labels:\\n\"\n",
    "    result += df['esci_label'].value_counts(normalize=True).to_string()\n",
    "    \n",
    "    result += \"\\n\\nSample query and its top 5 results:\\n\"\n",
    "    sample_query_idx = 0\n",
    "    sample_query = unique_queries[sample_query_idx]\n",
    "    result += f\"Query: {sample_query}\\n\"\n",
    "    \n",
    "    top_5_indices = indices[sample_query_idx][:5]\n",
    "    result += \"Top 5 results:\\n\"\n",
    "    for i, idx in enumerate(top_5_indices, 1):\n",
    "        product = unique_products.iloc[idx]\n",
    "        result += f\"{i}. {product['product_title']} (Product ID: {product['product_id']})\\n\"\n",
    "    \n",
    "    print(result) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_vector_index(embeddings, labels, n_samples=1000):\n",
    "    if len(embeddings) > n_samples:\n",
    "        indices = np.random.choice(len(embeddings), n_samples, replace=False)\n",
    "        embeddings = embeddings[indices]\n",
    "        labels = [labels[i] for i in indices]\n",
    "    \n",
    "    pca = PCA(n_components=50)\n",
    "    embeddings_pca = pca.fit_transform(embeddings)\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings_pca)\n",
    "    \n",
    "    #was not useful for inferencing how to improve performance, but lets one see the lack of singificant clustering in the vector indexes\n",
    "    #there is some general shape, likely product category group based, all of which is expected since its an amazon dataset\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels, cmap='viridis')\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(\"2D Visualization of Embeddings\")\n",
    "    plt.savefig(\"embeddings_visualization.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    distances = cosine_similarity(embeddings)\n",
    "    avg_distance = np.mean(distances)\n",
    "    std_distance = np.std(distances)\n",
    "    \n",
    "    return {\n",
    "        \"avg_distance\": avg_distance,\n",
    "        \"std_distance\": std_distance,\n",
    "        \"visualization\": \"embeddings_visualization.png\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving for reusability and extra testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_paths(folder, size):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    full_df = os.path.join(folder, f\"{size}full_df.pkl\")\n",
    "    embeddings = os.path.join(folder, f\"{size}embeddings.pkl\")\n",
    "    faiss_index = os.path.join(folder, f\"{size}faiss_index.pkl\")\n",
    "    bm25_index = os.path.join(folder, f\"{size}bm25_index.pkl\")\n",
    "    return full_df, embeddings, faiss_index, bm25_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_preprocess(full_df, sample_size):\n",
    "    if os.path.exists(full_df):\n",
    "        print(\"Loading preprocessed data from checkpoint...\")\n",
    "        df = load_checkpoint(full_df)\n",
    "    else:\n",
    "        print(\"Preprocessing data...\")\n",
    "        df = load_and_preprocess_data(sample_size=sample_size)\n",
    "        save_checkpoint(df, full_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_generate_embeddings(embeddings, df, model_name):\n",
    "    if os.path.exists(embeddings):\n",
    "        print(\"Loading embeddings from checkpoint...\")\n",
    "        data = load_checkpoint(embeddings)\n",
    "        query_emb = data['query']\n",
    "        product_emb = data['product']\n",
    "        unique_queries = data['unique_queries']\n",
    "        unique_products = data['unique_products']\n",
    "    else:\n",
    "        print(\"Generating embeddings...\")\n",
    "        model = SentenceTransformer(model_name)\n",
    "        query_emb, product_emb, unique_queries, unique_products = process_dataframe(df, model)\n",
    "        data = {\n",
    "            'query': query_emb,\n",
    "            'product': product_emb,\n",
    "            'unique_queries': unique_queries,\n",
    "            'unique_products': unique_products\n",
    "        }\n",
    "        save_checkpoint(data, embeddings)\n",
    "    return query_emb, product_emb, unique_queries, unique_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_build_faiss(faiss_index, product_emb):\n",
    "    if os.path.exists(faiss_index):\n",
    "        print(\"Loading FAISS index from checkpoint...\")\n",
    "        product_index = load_checkpoint(faiss_index)\n",
    "    else:\n",
    "        print(\"Building FAISS index...\")\n",
    "        product_index = build_faiss_index(product_emb)\n",
    "        save_checkpoint(product_index, faiss_index)\n",
    "    return product_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_build_bm25(bm25_index, unique_products):\n",
    "    if os.path.exists(bm25_index):\n",
    "        print(\"Loading BM25 index from checkpoint...\")\n",
    "        bm25 = load_checkpoint(bm25_index)\n",
    "    else:\n",
    "        print(\"Building BM25 index...\")\n",
    "        product_texts = unique_products.apply(lambda row: f\"{row['product_title']} {row['product_description']} {row['product_bullet_point']}\", axis=1).tolist()\n",
    "        bm25 = build_bm25_index(product_texts)\n",
    "        save_checkpoint(bm25, bm25_index)\n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_searches(product_index, query_emb, bm25, unique_queries, product_emb, unique_products):\n",
    "    print(\"Performing semantic search...\")\n",
    "    semantic_distances, semantic_indices = search_index(product_index, query_emb, k=10)\n",
    "\n",
    "    print(\"Performing hybrid search...\")\n",
    "    hybrid_results = []\n",
    "    for query, query_embedding in zip(unique_queries, query_emb):\n",
    "        results = hybrid_search(query, bm25, product_index, product_emb, query_embedding, unique_products.to_dict('records'))\n",
    "        hybrid_results.append(results)\n",
    "    return semantic_indices, hybrid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_analyze(df, unique_products, unique_queries, product_emb, query_emb, semantic_indices, hybrid_results):\n",
    "    inspection_results = inspect_data(df, unique_products, unique_queries, product_emb, query_emb, semantic_indices)\n",
    "\n",
    "    print(\"Evaluating semantic search rankings...\")\n",
    "    semantic_eval = evaluate_rankings(df, unique_queries, unique_products, semantic_indices)\n",
    "\n",
    "    print(\"Evaluating hybrid search rankings...\")\n",
    "    hybrid_eval = evaluate_rankings(df, unique_queries, unique_products, hybrid_results)\n",
    "\n",
    "    print(\"\\nSemantic Search Results:\")\n",
    "    for metric, score in semantic_eval.items():\n",
    "        print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "    print(\"\\nHybrid Search Results:\")\n",
    "    for metric, score in hybrid_eval.items():\n",
    "        print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "    print(\"Analyzing vector index...\")\n",
    "    label_encoder = {label: i for i, label in enumerate(['E', 'S', 'C', 'I'])}\n",
    "    encoded_labels = [label_encoder[label] for label in df['esci_label']]\n",
    "    index_analysis = analyze_vector_index(product_emb, encoded_labels)\n",
    "    print(\"Vector Index Analysis:\", index_analysis)\n",
    "\n",
    "    return inspection_results, semantic_eval, hybrid_eval, index_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(folder, size, sample_size, inspection_results, semantic_eval, hybrid_eval, index_analysis):\n",
    "    results_path = os.path.join(folder, f\"{size}results_receipt.txt\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        f.write(f\"Sample Size: {sample_size * 100}%\\n\\n\")\n",
    "        f.write(\"Data Inspection Results:\\n\")\n",
    "        f.write(inspection_results)\n",
    "        \n",
    "        f.write(\"\\n\\nSemantic Search Evaluation Results:\\n\")\n",
    "        for metric, score in semantic_eval.items():\n",
    "            f.write(f\"{metric}: {score:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\nHybrid Search Evaluation Results:\\n\")\n",
    "        for metric, score in hybrid_eval.items():\n",
    "            f.write(f\"{metric}: {score:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\nVector Index Analysis:\\n\")\n",
    "        f.write(str(index_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Loading examples dataset...\n",
      "Loading products dataset...\n",
      "Filtering data...\n",
      "Merging datasets...\n",
      "Sampling 1.0% of queries...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Desktop\\graingertakehome\\.conda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding products...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 191/191 [03:56<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FAISS index...\n",
      "Building FAISS index...\n",
      "Building BM25 index...\n",
      "Performing semantic search...\n",
      "Searching index...\n",
      "Performing hybrid search...\n",
      "\n",
      "Data Inspection:\n",
      "Total judgements: 6120\n",
      "Unique products: 6090\n",
      "Unique queries: 298\n",
      "Product embeddings shape: (6090, 384)\n",
      "Query embeddings shape: (298, 384)\n",
      "\n",
      "Distribution of ESCI labels:\n",
      "esci_label\n",
      "E    0.442647\n",
      "S    0.358333\n",
      "I    0.158660\n",
      "C    0.040359\n",
      "\n",
      "Sample query and its top 5 results:\n",
      "Query: .5 lead b ain\n",
      "Top 5 results:\n",
      "1. Pentel Ain Pencil Leads 0.5mm HB, 40 Leads X 5 Pack/total 200 Leads (Japan Import) [Komainu-Dou Original Package] (Product ID: B00N99GWZ6)\n",
      "2. Pentel Ain Pencil Leads 0.5mm 4B, 40 Leads X 5 Pack/total 200 Leads (Japan Import) [Komainu-Dou Original Package] (Product ID: B00PQY8XRC)\n",
      "3. Pentel Ain Pencil Leads 0.5mm 2B, 40 Leads X 5 Pack/total 200 Leads (Japan Import) [Komainu-Dou Original Package] (Product ID: B00MIIFX8G)\n",
      "4. Pentel Ain Stein Mechanical Pencil Lead, 0.5mm B, 40 Leads x 3 Pack (XC275B-3P) (Product ID: B004EHYH0Y)\n",
      "5. Pentel Ain Stein Mechanical Pencil Lead, 0.5mm B,2B,3B,4B (40 Leads) 1 Each + Original 5 Colors Sticky Notes (Product ID: B01HODH9QI)\n",
      "\n",
      "Evaluating semantic search rankings...\n",
      "Evaluating rankings...\n",
      "\n",
      "Debugging Information:\n",
      "\n",
      "Query: .5 lead b ain\n",
      "Rank 1: ID B00N99GWZ6, Title: Pentel Ain Pencil Leads 0.5mm HB, 40 Leads X 5 Pac..., Relevant: Yes\n",
      "Rank 2: ID B00PQY8XRC, Title: Pentel Ain Pencil Leads 0.5mm 4B, 40 Leads X 5 Pac..., Relevant: Yes\n",
      "Rank 3: ID B00MIIFX8G, Title: Pentel Ain Pencil Leads 0.5mm 2B, 40 Leads X 5 Pac..., Relevant: Yes\n",
      "Rank 4: ID B004EHYH0Y, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.5mm B, ..., Relevant: Yes\n",
      "Rank 5: ID B01HODH9QI, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.5mm B,2..., Relevant: Yes\n",
      "Rank 6: ID B008JF3RLC, Title: Pentel Mechanical Pencil Lead, Ain Stein, 0.5mm, 4..., Relevant: Yes\n",
      "Rank 7: ID B004NNPWL2, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.9mm 2B,..., Relevant: Yes\n",
      "Rank 8: ID B004EHYH18, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.5mm HB,..., Relevant: Yes\n",
      "Rank 9: ID B004EHYH2M, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.5mm 2B,..., Relevant: Yes\n",
      "Rank 10: ID B017Q9VRIQ, Title: Pentel 0.5 Refill 3-piece Set 3B2BBAS for PG1015/5..., Relevant: Yes\n",
      "\n",
      "Query: .50 cc syringe without needle\n",
      "Rank 1: ID B00Z7MQBA4, Title: 3cc 3ml Syringe Without Needle 100 Syringes Box Me..., Relevant: No\n",
      "Rank 2: ID B07GGQP7CQ, Title: Frienda 4 Pack Large Plastic Syringe for Scientifi..., Relevant: Yes\n",
      "Rank 3: ID B013WWFJX0, Title: Karlling Pack of 5 X 10 ml 10cc Syringes Without N..., Relevant: Yes\n",
      "Rank 4: ID B08QFGYYPH, Title: 20 Pack Plastic Syringes - 1ml / 3ml / 5ml / 10ml ..., Relevant: No\n",
      "Rank 5: ID B07PY77BHF, Title: DEPEPE 120pcs 1ml Luer Slip Tip Syringe with Caps,..., Relevant: Yes\n",
      "Rank 6: ID B07C71C1LH, Title: 3 Pcs 150ml Large Syringes, Sterile and Individual..., Relevant: No\n",
      "Rank 7: ID B01N01TO2O, Title: BSTEAN 1ml 1cc Syringe with Luer Slip Tip, No Need..., Relevant: Yes\n",
      "Rank 8: ID B00OAC21Y2, Title: Covidien 685784972530 Plastic 6 cc 1 Tsp. Slip Tip..., Relevant: Yes\n",
      "Rank 9: ID B07S8YF6KK, Title: 5ml Syringe with Cap (100 Pack) | Oral Dispenser W..., Relevant: No\n",
      "Rank 10: ID B08L1KD91R, Title: Syringes Without Needle, Large Plastic Syringe for..., Relevant: No\n",
      "\n",
      "Query: 0-3 month swimsuit boy\n",
      "Rank 1: ID B08ZS9C4L3, Title: HAPPYMA Newborn Infant Baby Boys Swimsuit One-Piec..., Relevant: Yes\n",
      "Rank 2: ID B085XW3T4X, Title: Baby Boys Swimsuit One Piece Toddlers Zipper Bathi..., Relevant: Yes\n",
      "Rank 3: ID B01MFENFJU, Title: Baby Beach One-Piece Swimsuit UPF 50+ -Sun Protect..., Relevant: Yes\n",
      "Rank 4: ID B07DH5WH3Z, Title: Baby Boys Toddlers Swimsuit UV Protection Rash Gua..., Relevant: Yes\n",
      "Rank 5: ID B01JRE98RU, Title: Baby Beach One-Piece Swimsuit UPF 50+ -Sun Protect..., Relevant: Yes\n",
      "Rank 6: ID B082V45PHM, Title: Baby Swim Trunks, Toddler Infant Swimsuit Bathing ..., Relevant: Yes\n",
      "Rank 7: ID B084RHK3MJ, Title: Baby Toddler Boys Girls One Piece Swimsuit Set Swi..., Relevant: No\n",
      "Rank 8: ID B075B4MQFK, Title: Baby Boy Girl Swimsuit One Piece Surfing Suits Bea..., Relevant: Yes\n",
      "Rank 9: ID B092RDCYKG, Title: SGMWVB Toddler Baby Boys Three-Pieces Swimwear Swi..., Relevant: Yes\n",
      "Rank 10: ID B091NTVR65, Title: Baby Boy Swim Trunks Toddler Infant Boys Swimsuit ..., Relevant: Yes\n",
      "\n",
      "Query: 0.5cc syringe without needle\n",
      "Rank 1: ID B00Z7MQBA4, Title: 3cc 3ml Syringe Without Needle 100 Syringes Box Me..., Relevant: No\n",
      "Rank 2: ID B013WWFJX0, Title: Karlling Pack of 5 X 10 ml 10cc Syringes Without N..., Relevant: No\n",
      "Rank 3: ID B07GGQP7CQ, Title: Frienda 4 Pack Large Plastic Syringe for Scientifi..., Relevant: No\n",
      "Rank 4: ID B01N01TO2O, Title: BSTEAN 1ml 1cc Syringe with Luer Slip Tip, No Need..., Relevant: No\n",
      "Rank 5: ID B07C71C1LH, Title: 3 Pcs 150ml Large Syringes, Sterile and Individual..., Relevant: Yes\n",
      "Rank 6: ID B08QFGYYPH, Title: 20 Pack Plastic Syringes - 1ml / 3ml / 5ml / 10ml ..., Relevant: Yes\n",
      "Rank 7: ID B08L1KD91R, Title: Syringes Without Needle, Large Plastic Syringe for..., Relevant: Yes\n",
      "Rank 8: ID B07PY77BHF, Title: DEPEPE 120pcs 1ml Luer Slip Tip Syringe with Caps,..., Relevant: Yes\n",
      "Rank 9: ID B01N7IJXO5, Title: 3cc Luer Lock Syringe (No Needle), Box of 100..., Relevant: No\n",
      "Rank 10: ID B00OAC21Y2, Title: Covidien 685784972530 Plastic 6 cc 1 Tsp. Slip Tip..., Relevant: No\n",
      "\n",
      "Query: 1 20 volt extension cord no it's not what i\n",
      "Rank 1: ID B07QTFDFX3, Title: Nema 5-20P Power Extension Cord, [UL CUL Listed] H..., Relevant: No\n",
      "Rank 2: ID B08G7Y4GTP, Title: SPARKING 20FT Cigarette Lighter Extension Cord 20F..., Relevant: No\n",
      "Rank 3: ID B00004SQF4, Title: Southwire 2588SW0002 Outdoor Cord-12/3 SJTW Heavy ..., Relevant: Yes\n",
      "Rank 4: ID B08CXL1CGB, Title: 25FT Cigarette Lighter Extension Cord 25FT - Male ..., Relevant: Yes\n",
      "Rank 5: ID B07GJYCKCY, Title: StarTech.com 1 ft Flat Extension Cord - NEMA 5-15R..., Relevant: No\n",
      "Rank 6: ID B019P9ZGGO, Title: IRON FORGE CABLE 25 ft Lighted Outdoor Extension C..., Relevant: No\n",
      "Rank 7: ID B00P68L9RO, Title: BESTEK 12.1ft/3.7m 12V 24V Cigarette Lighter Exten..., Relevant: Yes\n",
      "Rank 8: ID B073FDJ4NY, Title: FIRMERST 1875W Flat Plug 1Ft Extension Cord 15A fo..., Relevant: Yes\n",
      "Rank 9: ID B074759VVG, Title: SPARKING 10FT Cigarette Lighter Extension Cord 10F..., Relevant: Yes\n",
      "Rank 10: ID B015CFUEC6, Title: Nilight NI-WA-01C Cigarette Lighter Extension Cord..., Relevant: No\n",
      "Evaluating hybrid search rankings...\n",
      "Evaluating rankings...\n",
      "\n",
      "Debugging Information:\n",
      "\n",
      "Query: .5 lead b ain\n",
      "Rank 1: ID B004EHYH0Y, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.5mm B, ..., Relevant: Yes\n",
      "Rank 2: ID B017Q9VRIQ, Title: Pentel 0.5 Refill 3-piece Set 3B2BBAS for PG1015/5..., Relevant: Yes\n",
      "Rank 3: ID B01HODH9QI, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.5mm B,2..., Relevant: Yes\n",
      "Rank 4: ID B008JF3RLC, Title: Pentel Mechanical Pencil Lead, Ain Stein, 0.5mm, 4..., Relevant: Yes\n",
      "Rank 5: ID B004NNPWL2, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.9mm 2B,..., Relevant: Yes\n",
      "Rank 6: ID B004EHYH2M, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.5mm 2B,..., Relevant: Yes\n",
      "Rank 7: ID B004EHYH18, Title: Pentel Ain Stein Mechanical Pencil Lead, 0.5mm HB,..., Relevant: Yes\n",
      "Rank 8: ID B00MIIFX8G, Title: Pentel Ain Pencil Leads 0.5mm 2B, 40 Leads X 5 Pac..., Relevant: Yes\n",
      "Rank 9: ID B00PQY8XRC, Title: Pentel Ain Pencil Leads 0.5mm 4B, 40 Leads X 5 Pac..., Relevant: Yes\n",
      "Rank 10: ID B00N99GWZ6, Title: Pentel Ain Pencil Leads 0.5mm HB, 40 Leads X 5 Pac..., Relevant: Yes\n",
      "\n",
      "Query: .50 cc syringe without needle\n",
      "Rank 1: ID B00OAC21Y2, Title: Covidien 685784972530 Plastic 6 cc 1 Tsp. Slip Tip..., Relevant: Yes\n",
      "Rank 2: ID B07PY77BHF, Title: DEPEPE 120pcs 1ml Luer Slip Tip Syringe with Caps,..., Relevant: Yes\n",
      "Rank 3: ID B00Z7MQBA4, Title: 3cc 3ml Syringe Without Needle 100 Syringes Box Me..., Relevant: No\n",
      "Rank 4: ID B08L1KD91R, Title: Syringes Without Needle, Large Plastic Syringe for..., Relevant: No\n",
      "Rank 5: ID B01N01TO2O, Title: BSTEAN 1ml 1cc Syringe with Luer Slip Tip, No Need..., Relevant: Yes\n",
      "Rank 6: ID B07S8YF6KK, Title: 5ml Syringe with Cap (100 Pack) | Oral Dispenser W..., Relevant: No\n",
      "Rank 7: ID B08QFGYYPH, Title: 20 Pack Plastic Syringes - 1ml / 3ml / 5ml / 10ml ..., Relevant: No\n",
      "Rank 8: ID B07C71C1LH, Title: 3 Pcs 150ml Large Syringes, Sterile and Individual..., Relevant: No\n",
      "Rank 9: ID B013WWFJX0, Title: Karlling Pack of 5 X 10 ml 10cc Syringes Without N..., Relevant: Yes\n",
      "Rank 10: ID B07GGQP7CQ, Title: Frienda 4 Pack Large Plastic Syringe for Scientifi..., Relevant: Yes\n",
      "\n",
      "Query: 0-3 month swimsuit boy\n",
      "Rank 1: ID B07DH5WH3Z, Title: Baby Boys Toddlers Swimsuit UV Protection Rash Gua..., Relevant: Yes\n",
      "Rank 2: ID B08ZS9C4L3, Title: HAPPYMA Newborn Infant Baby Boys Swimsuit One-Piec..., Relevant: Yes\n",
      "Rank 3: ID B085XW3T4X, Title: Baby Boys Swimsuit One Piece Toddlers Zipper Bathi..., Relevant: Yes\n",
      "Rank 4: ID B075B4MQFK, Title: Baby Boy Girl Swimsuit One Piece Surfing Suits Bea..., Relevant: Yes\n",
      "Rank 5: ID B01JRE98RU, Title: Baby Beach One-Piece Swimsuit UPF 50+ -Sun Protect..., Relevant: Yes\n",
      "Rank 6: ID B01MFENFJU, Title: Baby Beach One-Piece Swimsuit UPF 50+ -Sun Protect..., Relevant: Yes\n",
      "Rank 7: ID B084RHK3MJ, Title: Baby Toddler Boys Girls One Piece Swimsuit Set Swi..., Relevant: No\n",
      "Rank 8: ID B092RDCYKG, Title: SGMWVB Toddler Baby Boys Three-Pieces Swimwear Swi..., Relevant: Yes\n",
      "Rank 9: ID B091NTVR65, Title: Baby Boy Swim Trunks Toddler Infant Boys Swimsuit ..., Relevant: Yes\n",
      "Rank 10: ID B082V45PHM, Title: Baby Swim Trunks, Toddler Infant Swimsuit Bathing ..., Relevant: Yes\n",
      "\n",
      "Query: 0.5cc syringe without needle\n",
      "Rank 1: ID B07PY77BHF, Title: DEPEPE 120pcs 1ml Luer Slip Tip Syringe with Caps,..., Relevant: Yes\n",
      "Rank 2: ID B00Z7MQBA4, Title: 3cc 3ml Syringe Without Needle 100 Syringes Box Me..., Relevant: No\n",
      "Rank 3: ID B08L1KD91R, Title: Syringes Without Needle, Large Plastic Syringe for..., Relevant: Yes\n",
      "Rank 4: ID B00OAC21Y2, Title: Covidien 685784972530 Plastic 6 cc 1 Tsp. Slip Tip..., Relevant: No\n",
      "Rank 5: ID B01N01TO2O, Title: BSTEAN 1ml 1cc Syringe with Luer Slip Tip, No Need..., Relevant: No\n",
      "Rank 6: ID B08QFGYYPH, Title: 20 Pack Plastic Syringes - 1ml / 3ml / 5ml / 10ml ..., Relevant: Yes\n",
      "Rank 7: ID B07C71C1LH, Title: 3 Pcs 150ml Large Syringes, Sterile and Individual..., Relevant: Yes\n",
      "Rank 8: ID B01N7IJXO5, Title: 3cc Luer Lock Syringe (No Needle), Box of 100..., Relevant: No\n",
      "Rank 9: ID B013WWFJX0, Title: Karlling Pack of 5 X 10 ml 10cc Syringes Without N..., Relevant: No\n",
      "Rank 10: ID B07GGQP7CQ, Title: Frienda 4 Pack Large Plastic Syringe for Scientifi..., Relevant: No\n",
      "\n",
      "Query: 1 20 volt extension cord no it's not what i\n",
      "Rank 1: ID B08G7Y4GTP, Title: SPARKING 20FT Cigarette Lighter Extension Cord 20F..., Relevant: No\n",
      "Rank 2: ID B08CXL1CGB, Title: 25FT Cigarette Lighter Extension Cord 25FT - Male ..., Relevant: Yes\n",
      "Rank 3: ID B019P9ZGGO, Title: IRON FORGE CABLE 25 ft Lighted Outdoor Extension C..., Relevant: No\n",
      "Rank 4: ID B07GJYCKCY, Title: StarTech.com 1 ft Flat Extension Cord - NEMA 5-15R..., Relevant: No\n",
      "Rank 5: ID B07QTFDFX3, Title: Nema 5-20P Power Extension Cord, [UL CUL Listed] H..., Relevant: No\n",
      "Rank 6: ID B074759VVG, Title: SPARKING 10FT Cigarette Lighter Extension Cord 10F..., Relevant: Yes\n",
      "Rank 7: ID B00004SQF4, Title: Southwire 2588SW0002 Outdoor Cord-12/3 SJTW Heavy ..., Relevant: Yes\n",
      "Rank 8: ID B073FDJ4NY, Title: FIRMERST 1875W Flat Plug 1Ft Extension Cord 15A fo..., Relevant: Yes\n",
      "Rank 9: ID B015CFUEC6, Title: Nilight NI-WA-01C Cigarette Lighter Extension Cord..., Relevant: No\n",
      "Rank 10: ID B00P68L9RO, Title: BESTEK 12.1ft/3.7m 12V 24V Cigarette Lighter Exten..., Relevant: Yes\n",
      "\n",
      "Semantic Search Results:\n",
      "mrr: 0.8405\n",
      "hits@1: 0.7752\n",
      "hits@5: 0.9262\n",
      "hits@10: 0.9497\n",
      "ndcg@10: 0.8592\n",
      "map: 0.8003\n",
      "precision@5: 0.7255\n",
      "recall@10: 0.9497\n",
      "\n",
      "Hybrid Search Results:\n",
      "mrr: 0.8343\n",
      "hits@1: 0.7617\n",
      "hits@5: 0.9262\n",
      "hits@10: 0.9497\n",
      "ndcg@10: 0.8587\n",
      "map: 0.8020\n",
      "precision@5: 0.7248\n",
      "recall@10: 0.9497\n",
      "Analyzing vector index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Desktop\\graingertakehome\\.conda\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Index Analysis: {'avg_distance': 0.1259541, 'std_distance': 0.114808895, 'visualization': 'embeddings_visualization.png'}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    sample_size = 0.01 #set as default for processing speed\n",
    "    folder = 'allminilml6_hybridtest/'\n",
    "    size = '1pct_'\n",
    "    model_name = \"all-MiniLM-L6-v2\"\n",
    "    \n",
    "    full_df, embeddings, faiss_index, bm25_index = setup_paths(folder, size)\n",
    "    \n",
    "    try:\n",
    "        df = load_or_preprocess(full_df, sample_size)\n",
    "        query_emb, product_emb, unique_queries, unique_products = load_or_generate_embeddings(embeddings, df, model_name)\n",
    "        product_index = load_or_build_faiss(faiss_index, product_emb)\n",
    "        bm25 = load_or_build_bm25(bm25_index, unique_products)\n",
    "        \n",
    "        semantic_indices, hybrid_results = perform_searches(product_index, query_emb, bm25, unique_queries, product_emb, unique_products)\n",
    "        \n",
    "        inspection_results, semantic_eval, hybrid_eval, index_analysis = evaluate_and_analyze(df, unique_products, unique_queries, product_emb, query_emb, semantic_indices, hybrid_results)\n",
    "        \n",
    "        save_results(folder, size, sample_size, inspection_results, semantic_eval, hybrid_eval, index_analysis)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
